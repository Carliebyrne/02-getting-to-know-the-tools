{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask dataframes on a cluster\n",
    "\n",
    "The aim of this afternoon's session is to show you how you can go smoothly from 'a pandas dataframe I can handle on my computer' to 'a huuuge dataframe that I can handle on a cluster of X computers using dask'\n",
    "\n",
    "[Dask](http://dask.pydata.org) is a library which provides advanced parallelism for analytics using familiar Python APIs like [pandas](pandas.pydata.org), [numpy](numpy.org) and [scikit-learn](scikit-learn.org)\n",
    "\n",
    "We'll take a look at how we can scale the groupby/apply approaches we learnt this morning to a bigger dataframe on a cluster\n",
    "\n",
    "Note that you actually need to have a cluster running for this to work. I've got some basic instructions for spinning up a cluster in Google Cloud in `../handouts/running_dask_gloud.md` but there's a lot of concepts to follow to get this running. If you want to try this locally on your own computer you can just install dask-distributed using conda (either in Anaconda Navigator or on the command line with `conda install dask distributed`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dask-data/nyc-taxi/2015/yellow_tripdata_2015-01.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-02.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-03.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-04.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-05.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-06.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-07.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-08.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-09.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-10.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-11.csv',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-12.csv',\n",
       " 'dask-data/nyc-taxi/2015/parquet.gz',\n",
       " 'dask-data/nyc-taxi/2015/parquet',\n",
       " 'dask-data/nyc-taxi/2015/yellow_tripdata_2015-01.parq']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem()\n",
    "s3.ls('dask-data/nyc-taxi/2015')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is too large to fit into Pandas on a single computer. However, it can fit in memory if we break it up into many small pieces and load these pieces onto different computers across a cluster.\n",
    "\n",
    "We connect a client to our Dask cluster, composed of one centralized dask-scheduler process and several dask-worker processes running on each of the machines in our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://35.201.26.78:80 -- Jupyter notebook',\n",
       " 'http://35.189.30.21:80 -- Dask dashboard',\n",
       " 'http://35.189.30.21:8786 -- Dask Client connection']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%!\n",
    "# Print the scheduler and \n",
    "export NAME=\"analytics\"\n",
    "export DASK_SCHEDULER=$(kubectl get svc --namespace default ${NAME}-dask-scheduler -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n",
    "export DASK_SCHEDULER_UI_IP=$(kubectl get svc --namespace default ${NAME}-dask-scheduler -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n",
    "export JUPYTER_NOTEBOOK_IP=$(kubectl get svc --namespace default ${NAME}-dask-jupyter -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n",
    "echo http://$JUPYTER_NOTEBOOK_IP:80 -- Jupyter notebook\n",
    "echo http://$DASK_SCHEDULER_UI_IP:80  -- Dask dashboard\n",
    "echo http://$DASK_SCHEDULER:8786    -- Dask Client connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "scheduler_ip = \"35.189.30.21\"\n",
    "scheduler_port = \"8786\"\n",
    "\n",
    "client = Client(f'{scheduler_ip}:{scheduler_port}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use dask to parse the CSVs into a dataframe which looks and feels like a dataframe on our machine but is really being stored on the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv('s3://dask-data/nyc-taxi/2015/*.csv',\n",
    "                 parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                 storage_options={'anon': True})\n",
    "df = client.persist(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "('from-delayed-46ea7b05ff8a6f822e37775846598836', 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/week02/lib/python3.6/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/week02/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/week02/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/week02/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, **kwargs)\u001b[0m\n\u001b[1;32m   2204\u001b[0m                                          \u001b[0mfifo_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfifo_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m                                          \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2206\u001b[0;31m                                          \u001b[0muser_priority\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpriority\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2207\u001b[0m                                          )\n\u001b[1;32m   2208\u001b[0m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/week02/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_graph_to_futures\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, priority, user_priority, resources, retries, fifo_timeout, actors)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m             \u001b[0mdependencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCancelledError\u001b[0m: ('from-delayed-46ea7b05ff8a6f822e37775846598836', 0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65295 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65318 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65279 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:64961 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65159 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65080 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:64922 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65199 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65041 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65121 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:64879 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:64891 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65238 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:64999 remote=tcp://35.189.30.21:8786>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.1.1.210:65094 remote=tcp://35.189.30.21:8786>\n",
      "distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: TimeoutError: [Errno 60] Operation timed out\n"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:week02]",
   "language": "python",
   "name": "conda-env-week02-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
