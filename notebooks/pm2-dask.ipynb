{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask dataframes on a cluster\n",
    "\n",
    "The aim of this afternoon's session is to show you how you can go smoothly from 'a pandas dataframe I can handle on my computer' to 'a huuuge dataframe that I can handle on a cluster of X computers using dask'\n",
    "\n",
    "[Dask](http://dask.pydata.org) is a library which provides advanced parallelism for analytics using familiar Python APIs like [pandas](pandas.pydata.org), [numpy](numpy.org) and [scikit-learn](scikit-learn.org)\n",
    "\n",
    "We'll take a look at how we can scale the groupby/apply approaches we learnt this morning to a bigger dataframe on a cluster\n",
    "\n",
    "Note that you actually need to have a cluster running for this to work. I've got some basic instructions for spinning up a cluster in Google Cloud in `../handouts/running_dask_gloud.md` but there's a lot of concepts to follow to get this running. If you want to try this locally on your own computer you can just install dask-distributed using conda (either in Anaconda Navigator or on the command line with `conda install dask distributed`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['core-skills-nyc-taxi/2017/green_tripdata_2017-07.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-02.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-04.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-01.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-06.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-09.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-03.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-05.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-10.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-08.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-12.csv',\n",
       " 'core-skills-nyc-taxi/2017/green_tripdata_2017-11.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gcsfs\n",
    "\n",
    "filesys = gcsfs.GCSFileSystem()\n",
    "filesys.ls('core-skills-nyc-taxi/2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is too large to fit into Pandas on a single computer. However, it can fit in memory if we break it up into many small pieces and load these pieces onto different computers across a cluster.\n",
    "\n",
    "We connect a client to our Dask cluster, composed of one centralized dask-scheduler process and several dask-worker processes running on each of the machines in our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://analytics-dask-scheduler:8786\n",
       "  <li><b>Dashboard: </b><a href='http://analytics-dask-scheduler:8787/status' target='_blank'>http://analytics-dask-scheduler:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.36.1.9:8786' processes=0 cores=0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use dask to parse the CSVs into a dataframe which looks and feels like a dataframe on our machine but is really being stored on the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv('gcs://core-skills-nyc-taxi/2017/green_tripdata_2017-*.csv',\n",
    "                 parse_dates=['lpep_pickup_datetime', 'lpep_dropoff_datetime'])\n",
    "df = client.persist(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df.passenger_count).trip_distance.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df.tip_amount > 0) & (df.fare_amount > 0)]    # filter out bad rows\n",
    "df2['tip_fraction'] = df2.tip_amount / df2.fare_amount  # make new column\n",
    "\n",
    "dayofweek = (df2.groupby(df2.tpep_pickup_datetime.dt.dayofweek)\n",
    "                .tip_fraction\n",
    "                .mean())\n",
    "hour      = (df2.groupby(df2.tpep_pickup_datetime.dt.hour)\n",
    "                .tip_fraction\n",
    "                .mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = c.persist(df.set_index('lpep_pickup_datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'VendorID': 'uint8',\n",
    "                'passenger_count': 'uint8',\n",
    "                'RateCodeID': 'uint8',\n",
    "                'payment_type': 'uint8'})\n",
    "\n",
    "df.to_parquet('gcs://core-skills-nyc-taxi/2017/green_tripdata.',\n",
    "              compression='snappy',\n",
    "              has_nulls=False,\n",
    "              object_encoding='utf8',\n",
    "              fixed_text={'store_and_fwd_flag': 1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
